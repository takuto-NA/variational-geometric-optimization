---
title: "Neural: Liquid Neural Networks and why LFM2.5 matters"
---

> このページで主に触る knob: Space。連続時間の状態。Functional。系列予測と尤度。Geometry。時間スケール。Discretization。数値積分。Algorithm。学習と推論の安定性

## Problem

実世界のセンサ系列や制御のように、入力分布が変わる状況で安定に動く系列モデルを作りたい。
そのために、隠れ状態を離散時間の更新則ではなく連続時間の力学として持たせる。

## なぜ Liquid Neural Network を導入するのか

導入動機は、系列モデルに次の要求が同時に来るからである。

- 同じモデルで複数の時間スケールを扱いたい
- 入力分布の変化に対して壊れにくくしたい
- オンデバイスの制約下で計算量とメモリを抑えたい

Liquid Neural Network は、状態の時間発展を連続時間の力学として書き、さらに時間スケールを入力や状態で変調できるようにする。
これにより、更新の速い成分と遅い成分を同じ状態表現の中で同居させやすくなる。

## 他の手法に比べて何が嬉しいのか

比較の軸は Space と Discretization と Geometry である。

### 離散時間 RNN 系との比較

RNN や LSTM や GRU は離散時間の更新則で状態を進める。
時間刻みが変わると設計と学習が不安定になりやすく、時間スケールの同居はゲート設計と学習に強く依存する。
Liquid Neural Network は連続時間として状態を定義し、時間スケールの扱いをモデルの内部構造に寄せられる。

### MTRNN との比較

MTRNN は時間スケールを分けた状態を持つという発想が中心にある。
一方で時間スケールは固定の時定数として設計で与えることが多い。
Liquid Neural Network は連続時間として状態を持ち、さらに入力や状態に応じて有効な時間スケールを変調する設計を狙う。

比較の翻訳キーは次である。

- **Space**: どちらも状態を時間スケールで分解して持つ
- **Geometry**: MTRNN は固定時定数により更新の硬さが決まりやすい。LNN は時定数自体を状態依存で動かすので前処理の自由度が増える
- **Discretization**: MTRNN は離散時間の更新として実装されることが多い。LNN は連続時間を出発点にし、数値積分で離散化する

### Transformer 系との比較

Transformer は注意機構で長距離依存を扱いやすいが、実装の主役は離散トークン列である。
物理系やセンサ系のような不規則サンプリングや時間刻みが混ざる状況では、前処理と位置の扱いが設計の中心になりやすい。
Liquid Neural Network は入力時刻を含む連続時間の系として書けるので、時間の扱いを Space と Discretization に一貫して押し込める。

### Neural ODE 系との比較

Neural ODE は連続時間の枠組みを提供するが、時間スケールは実装上の選択やネットワーク設計に分散しやすい。
Liquid time constant の設計は、時間スケールの変調を構造として前面に出す。
この差は、同じ連続時間でも Geometry と Discretization の設計自由度の置き場が違うという点に現れる。

### まとめ

Liquid Neural Network の嬉しさは次に要約できる。

- **時間スケールの同居**: 入力や状態に応じて有効な時間スケールを変えられる
- **頑健性の設計余地**: 時間の扱いを構造と離散化に押し込めるので、破綻点が見える
- **オンデバイス適性**: 同等精度をより小さい構造で狙う方針と相性が良い

## Liquid Neural Network の最小定義

Liquid Neural Network は、隠れ状態 $h(t)$ を連続時間で進める。
典型形は入力 $x(t)$ と状態 $h(t)$ に依存する微分方程式として書ける。

$$
\dot h(t)=f_\theta\big(h(t),x(t),t\big)
$$

ポイントは、時間スケールが固定ではなく入力や状態で変調される設計を持つことにある。
Liquid time constant と呼ばれる設計では、実装上はニューロンごとに有効な時定数が動く形になる。

## Functional

目的は通常の学習と同じで、系列に対する損失を最小化する。
分類なら交差エントロピー、回帰なら二乗誤差、言語モデルなら負の対数尤度になる。

$$
\theta^*=\arg\min_\theta\ \mathbb E\big[\ell(\text{model}_\theta,\text{data})\big]
$$

## Geometry (G, J)

- $J=0$。学習は散逸側として扱う
- $G$: Euclid を既定にできるが、連続時間のモデルでは時間方向のスケール選択が本質的な前処理になる  
  学習率や正規化に加えて、数値積分の誤差制御が更新の見え方を変える

## Discretization

連続時間モデルは実装では必ず離散化される。
設計自由度は次の通り。

- ODE をどの数値積分で解くか
- 誤差制御をどう設定するか
- どこで状態を保存し、どこで再計算するか

これは [app02-neural-ode](./app02-neural-ode) の離散化と同じ問題として読める。

## Algorithm

学習は次の 2 つの見方に分かれる。

- 離散化した計算グラフに対して reverse-mode AD を回す
- 連続の随伴方程式を立てて感度を計算する

どちらでも一次変分は共ベクトルとして得られ、更新方向は $G$ の選択で決まる。

## LFM2.5 を理解する上での位置づけ

Liquid AI の公開情報では、Liquid Neural Network の流れを基盤技術として発展させ、基盤モデルの系列として LFM を提示している。
LFM2.5 はオンデバイス用途を強く意識した LFM の世代であり、注意機構だけに依らないハイブリッド構造を採用している。

## LFM2.5 ではどのように使われているか

公開されているモデルカードの記述では、LFM2.5 は次のような構成になっている。

- 16 層
- 10 個の double gated LIV convolution blocks
- 6 個の GQA blocks

ここで注意が要る。
Liquid Neural Network という語は、狭い意味では連続時間の状態方程式と liquid time constant を指す。
一方で Liquid AI の公開情報では、Liquid の系譜はより広くブロック設計の枠組みとして説明される。
そのため LFM2.5 は LNN をそのまま積むというより、Liquid の考え方を使って設計した演算ブロックを混成したものとして読むのが自然である。

この構成から読める点は次の通り。

- LFM2.5 は Transformer だけではない  
  局所混合を担う畳み込み系のブロックと、文脈を担う注意ブロックを組み合わせている
- Liquid の使いどころはブロック設計にある  
  公開情報上で LNN の連続時間 ODE をそのまま LLM の中核として使うとは書かれていない  
  代わりに、入力に応じて振る舞いが変わるゲート付きの演算子群を、効率と安定性のために混ぜる方針が前面に出る

## 主要な役割は何が担っているか

以下は公開情報の構成を前提にした読み方である。
ブロック内部の数式レベルの詳細はここでは確定できない。
ただし役割分担はハイブリッド構造として一貫して説明できる。

### GQA blocks が担う役割

GQA は注意機構の変種であり、長距離の文脈統合を担当する。
言語モデルとしての能力面ではここが主役になる。

- **長距離依存**: 直近だけでなく遠いトークン間の関係を統合する
- **情報の再配置**: 重要な要素を取り出して次トークン生成に反映する
- **表現の整合**: 多層で同じ表現空間を更新し、文脈の一貫性を保つ

VGO では Space を系列の状態更新として見たとき、GQA は広い受容野の更新則を担う部分になる。

### double gated LIV convolution blocks が担う役割

畳み込み系ブロックは局所混合を担当する。
ゲートを持つので、入力に応じて通す情報と止める情報を変えられる。
オンデバイスでの速度と効率に対してここが主役になりやすい。

- **局所混合**: 近傍のトークンを軽い演算で混ぜる
- **高速な前処理**: 注意ブロックへ渡す表現を整える
- **ゲートによる適応**: 入力に応じて線形演算の有効成分を切り替える

VGO では Discretization と Geometry が効いてくる。
離散化されたブロックの選択そのものが推論コストを決め、ゲートや正規化は事実上の前処理として安定性とスケールを整える。

### なぜ両方が要るのか

オンデバイス志向の設計だと、全部を注意機構に寄せると計算量と帯域が重くなりやすい。
一方で全部を局所演算に寄せると文脈が弱くなりやすい。
そのため局所を畳み込み系で稼ぎ、長距離を注意で押さえる分業が合理的になる。

### まとめ

主要な役割は次の分担として理解するとズレにくい。

- **能力の核**: GQA blocks が文脈統合を担う
- **効率の核**: double gated LIV convolution blocks が局所混合と高速化を担う

VGO の翻訳キーで言い換えると次の形になる。

- **Space**: 状態を持つ構造を強く意識する。系列を力学として読む
- **Discretization**: 高速推論は離散化の設計に直結する。ブロック設計と実装の結合が強い
- **Geometry**: スケールと前処理が性能と安定性に直結する

理解のための翻訳キーは次の通り。

- **Space**: 状態を持つ構造を強く意識する。系列を力学として読む
- **Discretization**: 高速推論は離散化の設計に直結する。ブロック設計と実装の結合が強い
- **Geometry**: スケールと前処理が性能と安定性に直結する

モデルカードでは LFM2.5 が GQA と畳み込み系ブロックのハイブリッドとして記述されている。
ここは Liquid の系譜が効率性と安定性に寄与する部分として読むと理解しやすい。

## Notes

- **重要度**: LFM2.5 は系列モデルの設計を Algorithm だけでなく Space と Discretization の問題として見せる題材になる
- **実装難易度**: 中から高。数値積分と安定性の設計が要る
- **実装リスク**: 誤差制御とスケーリングに敏感になりやすい。学習設定だけでなく離散化が破綻点になる
- **参照**:
  - [Liquid AI Research: From Liquid Neural Networks to Liquid Foundation Models](https://www.liquid.ai/research/liquid-neural-networks-research)
  - [Liquid AI Blog: Introducing LFM2.5](https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-ai)
  - [Hugging Face: LiquidAI LFM2.5 models](https://huggingface.co/LiquidAI)

